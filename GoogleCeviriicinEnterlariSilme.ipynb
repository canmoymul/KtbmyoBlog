{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canmoymul/KtbmyoBlog/blob/master/GoogleCeviriicinEnterlariSilme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "haJ8xndA1-xw"
      },
      "outputs": [],
      "source": [
        "metin     = \"\"\"\n",
        "Autonomous driving is a complex task that is difficult to cast into algorithms.\n",
        "Therefore, researchers turn to deep neural networks that map front-facing camera\n",
        "data stream to the associated driving commands. The learned driving policy can be\n",
        "conditioned to respond to navigational commands, thus the vehicle can take specific\n",
        "turns in intersections to reach a destination. Such visual input-based technique is\n",
        "demonstrated to drive efficiently when deployed on the same training environments.\n",
        "Nevertheless, performance dramatically decreases in new environments and is not\n",
        "consistent against varying weather conditions. In this work, a proposed model\n",
        "copes with such two challenges by fusing laser scanner input with the camera.\n",
        "On CARLA urban driving benchmark, our model improves autonomous driving\n",
        "success rate and average distance traveled towards destination on all driving tasks\n",
        "and environments combinations, while it’s trained on automatically recorded traces.\n",
        "Generalization success rate improves by 52% and weather consistency improved\n",
        "by around four times.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gqp5YNuk516X"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qHVK-WYM2Hni"
      },
      "outputs": [],
      "source": [
        "entersil = metin.split(sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IHj29ab2Wng",
        "outputId": "6a7eafd8-4cb1-448f-e864-c1b7fe774854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'Autonomous driving is a complex task that is difficult to cast into algorithms.', 'Therefore, researchers turn to deep neural networks that map front-facing camera', 'data stream to the associated driving commands. The learned driving policy can be', 'conditioned to respond to navigational commands, thus the vehicle can take specific', 'turns in intersections to reach a destination. Such visual input-based technique is', 'demonstrated to drive efficiently when deployed on the same training environments.', 'Nevertheless, performance dramatically decreases in new environments and is not', 'consistent against varying weather conditions. In this work, a proposed model', 'copes with such two challenges by fusing laser scanner input with the camera.', 'On CARLA urban driving benchmark, our model improves autonomous driving', 'success rate and average distance traveled towards destination on all driving tasks', 'and environments combinations, while it’s trained on automatically recorded traces.', 'Generalization success rate improves by 52% and weather consistency improved', 'by around four times.', '', '']\n"
          ]
        }
      ],
      "source": [
        "print(entersil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "miGL1ecu2YrY"
      },
      "outputs": [],
      "source": [
        "metin = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DxTHnGPF2eOS"
      },
      "outputs": [],
      "source": [
        "for birlestir in entersil:\n",
        "  metin =metin + birlestir + \" \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6AjHApU4RDe",
        "outputId": "71b26b79-1492-42d7-c6a2-ac62a5c5d8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Autonomous driving is a complex task that is difficult to cast into algorithms. Therefore, researchers turn to deep neural networks that map front-facing camera data stream to the associated driving commands. The learned driving policy can be conditioned to respond to navigational commands, thus the vehicle can take specific turns in intersections to reach a destination. Such visual input-based technique is demonstrated to drive efficiently when deployed on the same training environments. Nevertheless, performance dramatically decreases in new environments and is not consistent against varying weather conditions. In this work, a proposed model copes with such two challenges by fusing laser scanner input with the camera. On CARLA urban driving benchmark, our model improves autonomous driving success rate and average distance traveled towards destination on all driving tasks and environments combinations, while it’s trained on automatically recorded traces. Generalization success rate improves by 52% and weather consistency improved by around four times.   \n"
          ]
        }
      ],
      "source": [
        "print(metin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6HddwJMQOCR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GoogleCeviriicinEnterlariSilme.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOK7qNGdpUrswD955O7AoqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}